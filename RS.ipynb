{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed9f4f-0e77-462b-abb7-616d77fc2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "\n",
    "# Cargar los datos\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b3a1c-9ec5-4462-b602-8154598d4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset MovieLens\n",
    "def load_movielens_data():\n",
    "    data = Dataset.load_builtin('ml-100k')\n",
    "    return data\n",
    "\n",
    "# Cargar los títulos de las películas\n",
    "def load_movie_titles():\n",
    "    # Ajusta la ruta para incluir la carpeta \"uk100\"\n",
    "    movie_titles = pd.read_csv('uk100/u.item', sep='|', encoding='latin-1', usecols=[0, 1], header=None)\n",
    "    movie_titles.columns = ['movie_id', 'title']\n",
    "    return movie_titles\n",
    "\n",
    "# Entrenar el modelo de recomendación\n",
    "def train_model(data):\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "    algo = SVD()\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    print(\"Rendimiento del modelo:\")\n",
    "    accuracy.rmse(predictions)\n",
    "    accuracy.mae(predictions)  # Cálculo de MAE\n",
    "    return algo, predictions, testset\n",
    "\n",
    "# Realizar recomendaciones personalizadas\n",
    "def recommend(algo, user_id, item_ids, n_recommendations=5):\n",
    "    recommendations = []\n",
    "    for item_id in item_ids:\n",
    "        pred = algo.predict(user_id, item_id)\n",
    "        recommendations.append((item_id, pred.est))\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:n_recommendations]\n",
    "\n",
    "# Mostrar las recomendaciones con títulos\n",
    "def display_recommendations(recommendations, movie_titles):\n",
    "    print(\"\\nRecomendaciones:\")\n",
    "    for movie_id, rating in recommendations:\n",
    "        title = movie_titles[movie_titles['movie_id'] == int(movie_id)]['title'].values[0]\n",
    "        print(f\"Película: {title}, Rating estimado: {rating:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar los datos\n",
    "    data = load_movielens_data()\n",
    "    \n",
    "    # Cargar los títulos de las películas\n",
    "    movie_titles = load_movie_titles()\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    algo, predictions, testset = train_model(data)\n",
    "    \n",
    "    # Listar los IDs de películas para un usuario (ejemplo)\n",
    "    user_id = '196'\n",
    "    all_item_ids = set(item for (_, item, _) in testset)  # Obtener películas en el set de prueba\n",
    "    \n",
    "    # Generar recomendaciones para el usuario 196\n",
    "    top_recommendations = recommend(algo, user_id, all_item_ids, n_recommendations=5)\n",
    "    display_recommendations(top_recommendations, movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069aa2e-60d6-4eac-bd94-9342e9d20af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Cargar el dataset MovieLens\n",
    "def load_movielens_data():\n",
    "    data = Dataset.load_builtin('ml-100k')\n",
    "    return data\n",
    "\n",
    "# Buscar los mejores hiperparámetros para el modelo SVD\n",
    "def find_best_hyperparameters(data):\n",
    "    # Definir el espacio de búsqueda para los hiperparámetros\n",
    "    param_grid = {\n",
    "        'n_factors': [50, 100, 150, 200],  # Número de factores latentes\n",
    "        'n_epochs': [20, 30, 50],          # Número de iteraciones en el entrenamiento\n",
    "        'lr_all': [0.002, 0.005, 0.01],    # Tasa de aprendizaje\n",
    "        'reg_all': [0.02, 0.1, 0.2, 0.4],  # Regularización\n",
    "        'biased': [True, False]            # Si se deben usar sesgos (biases)\n",
    "    }\n",
    "\n",
    "    # Usar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "    gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1, joblib_verbose=2)\n",
    "    gs.fit(data)\n",
    "    \n",
    "    # Resultados del mejor modelo\n",
    "    print(\"Mejores Hiperparámetros:\")\n",
    "    print(gs.best_params['rmse'])\n",
    "    print(f\"Mejor RMSE: {gs.best_score['rmse']}\")\n",
    "    print(f\"Mejor MAE: {gs.best_score['mae']}\")\n",
    "    \n",
    "    return gs.best_params['rmse'], gs.best_score['rmse'], gs.best_score['mae']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar los datos\n",
    "    data = load_movielens_data()\n",
    "\n",
    "    # Encontrar los mejores hiperparámetros\n",
    "    best_params, best_rmse, best_mae = find_best_hyperparameters(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4146a6-50d7-4067-a787-918cf08317d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset MovieLens\n",
    "def load_movielens_data():\n",
    "    data = Dataset.load_builtin('ml-100k')\n",
    "    return data\n",
    "\n",
    "# Cargar los títulos de las películas\n",
    "def load_movie_titles():\n",
    "    # Ajusta la ruta para incluir la carpeta \"uk100\"\n",
    "    movie_titles = pd.read_csv('uk100/u.item', sep='|', encoding='latin-1', usecols=[0, 1], header=None)\n",
    "    movie_titles.columns = ['movie_id', 'title']\n",
    "    return movie_titles\n",
    "\n",
    "# Entrenar el modelo de recomendación con los mejores hiperparámetros\n",
    "def train_model_with_best_params(data):\n",
    "    # Dividir el dataset en entrenamiento y prueba\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "    \n",
    "    # Entrenar el modelo con los mejores hiperparámetros\n",
    "    algo = SVD(n_factors=200, n_epochs=50, lr_all=0.01, reg_all=0.1, biased=True)\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    predictions = algo.test(testset)\n",
    "    \n",
    "    return algo, predictions, testset\n",
    "\n",
    "# Realizar recomendaciones personalizadas\n",
    "def recommend(algo, user_id, item_ids, n_recommendations=5):\n",
    "    recommendations = []\n",
    "    for item_id in item_ids:\n",
    "        pred = algo.predict(user_id, item_id)\n",
    "        recommendations.append((item_id, pred.est))\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:n_recommendations]\n",
    "\n",
    "# Mostrar las recomendaciones con títulos\n",
    "def display_recommendations(recommendations, movie_titles):\n",
    "    print(\"\\nRecomendaciones:\")\n",
    "    for movie_id, rating in recommendations:\n",
    "        title = movie_titles[movie_titles['movie_id'] == int(movie_id)]['title'].values[0]\n",
    "        print(f\"Película: {title}, Rating estimado: {rating:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar los datos\n",
    "    data = load_movielens_data()\n",
    "    \n",
    "    # Cargar los títulos de las películas\n",
    "    movie_titles = load_movie_titles()\n",
    "    \n",
    "    # Entrenar el modelo con los mejores hiperparámetros\n",
    "    algo, predictions, testset = train_model_with_best_params(data)\n",
    "    \n",
    "    # Mostrar métricas de evaluación\n",
    "    print(\"Evaluación del modelo con los mejores hiperparámetros:\")\n",
    "    print(\"RMSE:\", accuracy.rmse(predictions, verbose=False))  # Solo imprimir RMSE\n",
    "    print(\"MAE:\", accuracy.mae(predictions, verbose=False))    # Solo imprimir MAE\n",
    "    \n",
    "    # Listar los IDs de películas para un usuario (ejemplo)\n",
    "    user_id = '196'\n",
    "    all_item_ids = set(item for (_, item, _) in testset)  # Obtener películas en el set de prueba\n",
    "    \n",
    "    # Generar recomendaciones para el usuario 196\n",
    "    top_recommendations = recommend(algo, user_id, all_item_ids, n_recommendations=5)\n",
    "    display_recommendations(top_recommendations, movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b8431-8e5c-4056-8dce-5837319303dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Funciones para el análisis de datos y el modelo\n",
    "def load_movielens_data():\n",
    "    data = Dataset.load_builtin('ml-100k')\n",
    "    return data\n",
    "\n",
    "def train_model(data):\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "    algo = SVD()\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    print(\"Rendimiento del modelo:\")\n",
    "    accuracy.rmse(predictions)\n",
    "    return algo, predictions, testset\n",
    "\n",
    "# Funciones de visualización\n",
    "def plot_rating_distribution(predictions):\n",
    "    estimated_ratings = [pred.est for pred in predictions]\n",
    "    plt.hist(estimated_ratings, bins=10, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(\"Distribución de Calificaciones Estimadas\")\n",
    "    plt.xlabel(\"Calificación Estimada\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_actual_vs_predicted(predictions):\n",
    "    actual_ratings = [pred.r_ui for pred in predictions]  # Calificaciones reales\n",
    "    estimated_ratings = [pred.est for pred in predictions]  # Calificaciones estimadas\n",
    "    \n",
    "    plt.scatter(actual_ratings, estimated_ratings, alpha=0.6)\n",
    "    plt.plot([min(actual_ratings), max(actual_ratings)], [min(actual_ratings), max(actual_ratings)], 'r--')\n",
    "    plt.title(\"Comparación entre Calificaciones Reales y Estimadas\")\n",
    "    plt.xlabel(\"Calificación Real\")\n",
    "    plt.ylabel(\"Calificación Estimada\")\n",
    "    plt.grid(alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals(predictions):\n",
    "    residuals = [pred.r_ui - pred.est for pred in predictions]  # Diferencia entre real y estimada\n",
    "    \n",
    "    plt.hist(residuals, bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
    "    plt.title(\"Distribución de los Errores de Predicción (Residuales)\")\n",
    "    plt.xlabel(\"Error de Predicción (Real - Estimado)\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_ratings_per_user(data):\n",
    "    df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    ratings_per_user = df.groupby('user_id').size()\n",
    "    \n",
    "    plt.hist(ratings_per_user, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "    plt.title(\"Distribución del Número de Calificaciones por Usuario\")\n",
    "    plt.xlabel(\"Número de Calificaciones\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_ratings_per_movie(data):\n",
    "    df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    ratings_per_movie = df.groupby('item_id').size()\n",
    "    \n",
    "    plt.hist(ratings_per_movie, bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "    plt.title(\"Distribución del Número de Calificaciones por Película\")\n",
    "    plt.xlabel(\"Número de Calificaciones\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_avg_rating_per_user(data):\n",
    "    df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    avg_ratings_per_user = df.groupby('user_id')['rating'].mean()\n",
    "    \n",
    "    plt.hist(avg_ratings_per_user, bins=20, alpha=0.7, color='cyan', edgecolor='black')\n",
    "    plt.title(\"Distribución de las Calificaciones Promedio por Usuario\")\n",
    "    plt.xlabel(\"Calificación Promedio\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_avg_rating_per_movie(data):\n",
    "    df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    avg_ratings_per_movie = df.groupby('item_id')['rating'].mean()\n",
    "    \n",
    "    plt.hist(avg_ratings_per_movie, bins=20, alpha=0.7, color='red', edgecolor='black')\n",
    "    plt.title(\"Distribución de las Calificaciones Promedio por Película\")\n",
    "    plt.xlabel(\"Calificación Promedio\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_heatmap(predictions, top_n_users=50, top_n_items=50):\n",
    "    errors = pd.DataFrame({\n",
    "        'user_id': [pred.uid for pred in predictions],\n",
    "        'item_id': [pred.iid for pred in predictions],\n",
    "        'error': [abs(pred.r_ui - pred.est) for pred in predictions]\n",
    "    })\n",
    "    \n",
    "    # Filtrar los usuarios y los ítems con más datos\n",
    "    top_users = errors['user_id'].value_counts().head(top_n_users).index\n",
    "    top_items = errors['item_id'].value_counts().head(top_n_items).index\n",
    "    \n",
    "    filtered_errors = errors[errors['user_id'].isin(top_users) & errors['item_id'].isin(top_items)]\n",
    "    pivot_table = filtered_errors.pivot_table(index='user_id', columns='item_id', values='error', fill_value=0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_table, cmap='coolwarm', cbar=True, annot=False, fmt=\".1f\", linewidths=0.5)\n",
    "    plt.title(f\"Heatmap de Errores de Predicción: Top {top_n_users} Usuarios y {top_n_items} Ítems\")\n",
    "    plt.xlabel(\"Ítem\")\n",
    "    plt.ylabel(\"Usuario\")\n",
    "    plt.show()\n",
    "\n",
    "# Bloque principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar datos\n",
    "    data = load_movielens_data()\n",
    "    \n",
    "    # Entrenar el modelo y obtener predicciones\n",
    "    algo, predictions, testset = train_model(data)\n",
    "    \n",
    "    # Generar gráficos\n",
    "    plot_rating_distribution(predictions)\n",
    "    plot_actual_vs_predicted(predictions)\n",
    "    plot_residuals(predictions)\n",
    "    plot_ratings_per_user(data)\n",
    "    plot_ratings_per_movie(data)\n",
    "    plot_avg_rating_per_user(data)\n",
    "    plot_avg_rating_per_movie(data)\n",
    "    plot_error_heatmap(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cde1e4-b310-41fc-a78a-eb158feec1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
